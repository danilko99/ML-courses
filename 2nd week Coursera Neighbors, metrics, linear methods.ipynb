{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "import numpy\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "data = pandas.read_csv('wine.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[0]\n",
    "X = data.loc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x0000027342ECD750>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.77777778, 0.66666667, 0.72222222, 0.71428571, 0.77142857]),\n",
       " array([0.72222222, 0.63888889, 0.69444444, 0.57142857, 0.68571429]),\n",
       " array([0.80555556, 0.61111111, 0.63888889, 0.65714286, 0.82857143]),\n",
       " array([0.75      , 0.52777778, 0.61111111, 0.65714286, 0.74285714]),\n",
       " array([0.72222222, 0.61111111, 0.61111111, 0.68571429, 0.74285714]),\n",
       " array([0.72222222, 0.63888889, 0.63888889, 0.68571429, 0.68571429]),\n",
       " array([0.69444444, 0.58333333, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.72222222, 0.61111111, 0.66666667, 0.65714286, 0.74285714]),\n",
       " array([0.72222222, 0.63888889, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.72222222, 0.61111111, 0.63888889, 0.68571429, 0.74285714]),\n",
       " array([0.75      , 0.63888889, 0.66666667, 0.71428571, 0.74285714]),\n",
       " array([0.72222222, 0.66666667, 0.69444444, 0.68571429, 0.71428571]),\n",
       " array([0.72222222, 0.69444444, 0.66666667, 0.65714286, 0.71428571]),\n",
       " array([0.72222222, 0.66666667, 0.72222222, 0.6       , 0.68571429]),\n",
       " array([0.75      , 0.72222222, 0.69444444, 0.62857143, 0.71428571]),\n",
       " array([0.72222222, 0.63888889, 0.72222222, 0.6       , 0.71428571]),\n",
       " array([0.77777778, 0.72222222, 0.72222222, 0.6       , 0.68571429]),\n",
       " array([0.77777778, 0.61111111, 0.69444444, 0.6       , 0.71428571]),\n",
       " array([0.77777778, 0.63888889, 0.69444444, 0.6       , 0.68571429]),\n",
       " array([0.77777778, 0.61111111, 0.69444444, 0.62857143, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.75      , 0.62857143, 0.71428571]),\n",
       " array([0.77777778, 0.63888889, 0.69444444, 0.62857143, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.72222222, 0.6       , 0.77142857]),\n",
       " array([0.77777778, 0.63888889, 0.75      , 0.62857143, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.75      , 0.62857143, 0.71428571]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.65714286, 0.71428571]),\n",
       " array([0.77777778, 0.63888889, 0.72222222, 0.62857143, 0.71428571]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.58333333, 0.72222222, 0.62857143, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.61111111, 0.75      , 0.68571429, 0.74285714]),\n",
       " array([0.83333333, 0.61111111, 0.75      , 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.66666667, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.83333333, 0.61111111, 0.69444444, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.75      , 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.83333333, 0.61111111, 0.72222222, 0.71428571, 0.71428571]),\n",
       " array([0.75      , 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(1,51):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    scores.append(cross_val_score(knn, X, y, cv=kf))\n",
    "scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = numpy.mean(scores,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.730476\n",
       "35    0.724603\n",
       "34    0.724603\n",
       "48    0.719048\n",
       "36    0.713492\n",
       "29    0.713492\n",
       "32    0.713492\n",
       "33    0.713492\n",
       "41    0.713492\n",
       "38    0.713492\n",
       "37    0.713492\n",
       "3     0.708254\n",
       "28    0.707937\n",
       "30    0.707937\n",
       "39    0.707937\n",
       "50    0.707778\n",
       "40    0.707778\n",
       "43    0.707778\n",
       "44    0.707778\n",
       "45    0.707778\n",
       "46    0.707778\n",
       "42    0.707778\n",
       "24    0.707619\n",
       "11    0.702540\n",
       "9     0.702381\n",
       "23    0.702063\n",
       "15    0.701905\n",
       "21    0.701905\n",
       "25    0.701905\n",
       "17    0.701587\n",
       "47    0.696667\n",
       "12    0.696667\n",
       "49    0.696667\n",
       "26    0.696508\n",
       "22    0.696508\n",
       "27    0.696349\n",
       "31    0.690952\n",
       "13    0.690952\n",
       "20    0.690952\n",
       "10    0.680159\n",
       "7     0.680000\n",
       "8     0.680000\n",
       "16    0.679524\n",
       "18    0.679524\n",
       "14    0.679365\n",
       "19    0.679365\n",
       "5     0.674603\n",
       "6     0.674286\n",
       "2     0.662540\n",
       "4     0.657778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(scores, range(1, 51)).mean(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.94444444, 0.94444444, 0.91666667, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.88888889, 0.91666667, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.91666667, 0.94444444, 0.94285714, 0.94285714]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.91428571, 0.97142857]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.94285714, 0.97142857]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.94285714, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.91428571, 1.        ]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.91666667, 0.94444444, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.88888889, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.88888889, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 0.94285714])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2 = []\n",
    "\n",
    "for i in range(1,51):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    scores2.append(cross_val_score(knn, scale(X), y, cv=kf))\n",
    "scores2    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    0.977619\n",
       "16    0.972063\n",
       "15    0.972063\n",
       "18    0.966508\n",
       "17    0.966508\n",
       "20    0.966508\n",
       "22    0.966508\n",
       "14    0.966349\n",
       "28    0.966349\n",
       "33    0.966349\n",
       "34    0.966349\n",
       "43    0.966349\n",
       "41    0.966349\n",
       "45    0.966349\n",
       "21    0.960952\n",
       "11    0.960952\n",
       "23    0.960952\n",
       "38    0.960794\n",
       "9     0.960794\n",
       "10    0.960794\n",
       "26    0.960794\n",
       "39    0.960794\n",
       "42    0.960794\n",
       "30    0.960794\n",
       "32    0.960794\n",
       "40    0.960794\n",
       "35    0.960794\n",
       "36    0.960794\n",
       "44    0.960635\n",
       "50    0.960635\n",
       "19    0.955397\n",
       "12    0.955238\n",
       "8     0.955238\n",
       "25    0.955238\n",
       "24    0.955238\n",
       "27    0.955238\n",
       "31    0.955238\n",
       "37    0.955238\n",
       "49    0.955079\n",
       "47    0.955079\n",
       "3     0.955079\n",
       "46    0.949524\n",
       "48    0.949524\n",
       "7     0.949524\n",
       "6     0.949524\n",
       "13    0.949524\n",
       "5     0.949365\n",
       "1     0.943968\n",
       "4     0.938254\n",
       "2     0.932857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(scores2, range(1, 51)).mean(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "b = sklearn.datasets.load_boston()\n",
    "X = b.data\n",
    "y = b.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = numpy.linspace(1,10,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors = 5, weights = 'distance',metric = 'minkowski', p = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.38682375, -17.01103269, -22.15189604, -19.90670903,\n",
       "       -20.32384263])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X, y, cv=kf,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 -16.030646734221644 1.0\n",
      "-100 -16.030646734221644 1.0\n",
      "-16.030646734221644 -16.40783870832999 1.0452261306532664\n",
      "-16.030646734221644 -16.370696947059045 1.0904522613065326\n",
      "-16.030646734221644 -16.445716308439433 1.135678391959799\n",
      "-16.030646734221644 -16.475057773399403 1.1809045226130652\n",
      "-16.030646734221644 -16.526432329318258 1.2261306532663316\n",
      "-16.030646734221644 -16.636709345898257 1.271356783919598\n",
      "-16.030646734221644 -16.82422425426731 1.3165829145728645\n",
      "-16.030646734221644 -16.874209056598744 1.3618090452261307\n",
      "-16.030646734221644 -17.124898819792115 1.4070351758793969\n",
      "-16.030646734221644 -17.145231882153887 1.4522613065326633\n",
      "-16.030646734221644 -17.01936008026763 1.4974874371859297\n",
      "-16.030646734221644 -17.09913173771377 1.542713567839196\n",
      "-16.030646734221644 -16.801326640288362 1.5879396984924623\n",
      "-16.030646734221644 -16.980745198189776 1.6331658291457287\n",
      "-16.030646734221644 -17.03345890364771 1.678391959798995\n",
      "-16.030646734221644 -17.17164190266228 1.7236180904522613\n",
      "-16.030646734221644 -17.181679169045047 1.7688442211055277\n",
      "-16.030646734221644 -17.20826374287096 1.814070351758794\n",
      "-16.030646734221644 -17.32368019839837 1.8592964824120604\n",
      "-16.030646734221644 -17.415118891722805 1.9045226130653266\n",
      "-16.030646734221644 -17.385662319793234 1.949748743718593\n",
      "-16.030646734221644 -17.326038597662453 1.9949748743718594\n",
      "-16.030646734221644 -17.336966976165666 2.040201005025126\n",
      "-16.030646734221644 -17.382648653849692 2.085427135678392\n",
      "-16.030646734221644 -17.656697514147996 2.1306532663316586\n",
      "-16.030646734221644 -17.569894502250555 2.1758793969849246\n",
      "-16.030646734221644 -17.319503281094065 2.221105527638191\n",
      "-16.030646734221644 -17.504732498340466 2.2663316582914574\n",
      "-16.030646734221644 -17.5544941795893 2.3115577889447234\n",
      "-16.030646734221644 -17.566035281733512 2.35678391959799\n",
      "-16.030646734221644 -17.596032653116758 2.4020100502512562\n",
      "-16.030646734221644 -17.59909719750166 2.4472361809045227\n",
      "-16.030646734221644 -17.282256557226717 2.492462311557789\n",
      "-16.030646734221644 -17.326364532505202 2.5376884422110555\n",
      "-16.030646734221644 -17.485164572655087 2.582914572864322\n",
      "-16.030646734221644 -17.46023662680475 2.628140703517588\n",
      "-16.030646734221644 -17.47743618990552 2.6733668341708543\n",
      "-16.030646734221644 -17.54616768641742 2.7185929648241207\n",
      "-16.030646734221644 -17.528053717549938 2.7638190954773867\n",
      "-16.030646734221644 -17.61469632990715 2.809045226130653\n",
      "-16.030646734221644 -17.608471489929777 2.8542713567839195\n",
      "-16.030646734221644 -17.6500839868047 2.899497487437186\n",
      "-16.030646734221644 -17.889130893742156 2.9447236180904524\n",
      "-16.030646734221644 -17.885633475989607 2.9899497487437188\n",
      "-16.030646734221644 -18.10186246009226 3.035175879396985\n",
      "-16.030646734221644 -18.149154780822307 3.080402010050251\n",
      "-16.030646734221644 -18.22220320950366 3.1256281407035176\n",
      "-16.030646734221644 -18.279517840149946 3.170854271356784\n",
      "-16.030646734221644 -18.284410384858443 3.2160804020100504\n",
      "-16.030646734221644 -18.28084248158377 3.261306532663317\n",
      "-16.030646734221644 -18.214715094165346 3.306532663316583\n",
      "-16.030646734221644 -18.515185280996 3.351758793969849\n",
      "-16.030646734221644 -18.47144683695807 3.3969849246231156\n",
      "-16.030646734221644 -18.575451414274045 3.442211055276382\n",
      "-16.030646734221644 -18.586865033363814 3.4874371859296485\n",
      "-16.030646734221644 -18.850095290052927 3.532663316582915\n",
      "-16.030646734221644 -18.8876668848972 3.577889447236181\n",
      "-16.030646734221644 -18.931673277009743 3.6231155778894473\n",
      "-16.030646734221644 -18.937315926180123 3.6683417085427137\n",
      "-16.030646734221644 -18.910467174710746 3.71356783919598\n",
      "-16.030646734221644 -18.9132121646769 3.7587939698492465\n",
      "-16.030646734221644 -19.01464670258458 3.8040201005025125\n",
      "-16.030646734221644 -19.061420855938177 3.849246231155779\n",
      "-16.030646734221644 -19.049791170730238 3.8944723618090453\n",
      "-16.030646734221644 -19.07818772337484 3.9396984924623117\n",
      "-16.030646734221644 -19.16528652866065 3.984924623115578\n",
      "-16.030646734221644 -19.173754771167346 4.030150753768844\n",
      "-16.030646734221644 -19.13084222644743 4.075376884422111\n",
      "-16.030646734221644 -19.099267941871084 4.1206030150753765\n",
      "-16.030646734221644 -19.12475772862611 4.165829145728644\n",
      "-16.030646734221644 -19.073015312648188 4.211055276381909\n",
      "-16.030646734221644 -19.289888165237425 4.256281407035176\n",
      "-16.030646734221644 -19.299829999167464 4.301507537688442\n",
      "-16.030646734221644 -19.299315809385764 4.346733668341709\n",
      "-16.030646734221644 -19.306525774552377 4.391959798994975\n",
      "-16.030646734221644 -19.211694767941964 4.437185929648241\n",
      "-16.030646734221644 -19.197623949745598 4.482412060301508\n",
      "-16.030646734221644 -19.249063647978804 4.527638190954773\n",
      "-16.030646734221644 -19.407609005575047 4.572864321608041\n",
      "-16.030646734221644 -19.468588550690725 4.618090452261306\n",
      "-16.030646734221644 -19.480380362924432 4.6633165829145735\n",
      "-16.030646734221644 -19.577443558088486 4.708542713567839\n",
      "-16.030646734221644 -19.67292607910183 4.7537688442211055\n",
      "-16.030646734221644 -19.68423856503004 4.798994974874372\n",
      "-16.030646734221644 -19.731419398024357 4.844221105527638\n",
      "-16.030646734221644 -19.73336910414023 4.889447236180905\n",
      "-16.030646734221644 -19.738696325445968 4.934673366834171\n",
      "-16.030646734221644 -19.769988446644323 4.9798994974874375\n",
      "-16.030646734221644 -19.670338059212803 5.025125628140704\n",
      "-16.030646734221644 -19.67431393586822 5.07035175879397\n",
      "-16.030646734221644 -19.632889893449047 5.115577889447236\n",
      "-16.030646734221644 -19.659695780237264 5.160804020100502\n",
      "-16.030646734221644 -19.649106525992945 5.206030150753769\n",
      "-16.030646734221644 -19.677148886213153 5.251256281407035\n",
      "-16.030646734221644 -19.64968090362701 5.296482412060302\n",
      "-16.030646734221644 -19.654275491776183 5.341708542713568\n",
      "-16.030646734221644 -19.682205525268134 5.386934673366834\n",
      "-16.030646734221644 -19.685318799221008 5.432160804020101\n",
      "-16.030646734221644 -19.72242336689309 5.477386934673367\n",
      "-16.030646734221644 -19.884897890673262 5.522613065326634\n",
      "-16.030646734221644 -19.863082221331105 5.5678391959799\n",
      "-16.030646734221644 -19.878939440146766 5.613065326633166\n",
      "-16.030646734221644 -19.906251282633093 5.658291457286432\n",
      "-16.030646734221644 -19.910320385587006 5.703517587939698\n",
      "-16.030646734221644 -19.902438102260955 5.748743718592965\n",
      "-16.030646734221644 -20.11253710184381 5.793969849246231\n",
      "-16.030646734221644 -20.29319147728561 5.839195979899498\n",
      "-16.030646734221644 -20.29715786114856 5.884422110552764\n",
      "-16.030646734221644 -20.175003396044353 5.9296482412060305\n",
      "-16.030646734221644 -20.121621866892987 5.974874371859297\n",
      "-16.030646734221644 -20.12499079276851 6.020100502512563\n",
      "-16.030646734221644 -20.125536942150937 6.06532663316583\n",
      "-16.030646734221644 -20.076299776973105 6.110552763819095\n",
      "-16.030646734221644 -20.051248033114454 6.155778894472362\n",
      "-16.030646734221644 -20.040849575084636 6.201005025125628\n",
      "-16.030646734221644 -20.048463589548376 6.2462311557788945\n",
      "-16.030646734221644 -20.054179834596436 6.291457286432161\n",
      "-16.030646734221644 -20.542085209320767 6.336683417085427\n",
      "-16.030646734221644 -20.555924198317747 6.381909547738694\n",
      "-16.030646734221644 -20.55874023764605 6.42713567839196\n",
      "-16.030646734221644 -20.607239049053742 6.472361809045227\n",
      "-16.030646734221644 -20.58733687906359 6.517587939698493\n",
      "-16.030646734221644 -20.59802814044119 6.562814070351759\n",
      "-16.030646734221644 -20.58396733644139 6.608040201005025\n",
      "-16.030646734221644 -20.580163334500998 6.653266331658291\n",
      "-16.030646734221644 -20.588575011809407 6.698492462311558\n",
      "-16.030646734221644 -20.603890564541302 6.743718592964824\n",
      "-16.030646734221644 -20.60490740992562 6.788944723618091\n",
      "-16.030646734221644 -20.602554960427376 6.834170854271357\n",
      "-16.030646734221644 -20.60520435828845 6.8793969849246235\n",
      "-16.030646734221644 -20.607526973699628 6.92462311557789\n",
      "-16.030646734221644 -20.652383646486303 6.969849246231156\n",
      "-16.030646734221644 -20.67160266794708 7.015075376884423\n",
      "-16.030646734221644 -20.687580712184765 7.060301507537688\n",
      "-16.030646734221644 -20.69126542796107 7.105527638190955\n",
      "-16.030646734221644 -20.677962354617563 7.150753768844221\n",
      "-16.030646734221644 -20.680109742003737 7.1959798994974875\n",
      "-16.030646734221644 -20.879258126322675 7.241206030150754\n",
      "-16.030646734221644 -20.97868984749678 7.28643216080402\n",
      "-16.030646734221644 -20.993715767097477 7.331658291457287\n",
      "-16.030646734221644 -20.995591100386992 7.376884422110553\n",
      "-16.030646734221644 -21.00948881592416 7.42211055276382\n",
      "-16.030646734221644 -21.01130037767064 7.467336683417086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16.030646734221644 -21.013081934167804 7.5125628140703515\n",
      "-16.030646734221644 -21.0148340985596 7.557788944723618\n",
      "-16.030646734221644 -21.017417638850496 7.603015075376884\n",
      "-16.030646734221644 -21.01086496090104 7.648241206030151\n",
      "-16.030646734221644 -21.029703207238985 7.693467336683417\n",
      "-16.030646734221644 -21.02242241833668 7.738693467336684\n",
      "-16.030646734221644 -21.02402904696275 7.78391959798995\n",
      "-16.030646734221644 -21.057853494649535 7.8291457286432165\n",
      "-16.030646734221644 -21.0656423085044 7.874371859296483\n",
      "-16.030646734221644 -21.06698490725231 7.919597989949749\n",
      "-16.030646734221644 -21.068482443357823 7.964824120603016\n",
      "-16.030646734221644 -21.06818327983064 8.010050251256281\n",
      "-16.030646734221644 -21.071034728064937 8.055276381909547\n",
      "-16.030646734221644 -21.02558771191022 8.100502512562814\n",
      "-16.030646734221644 -20.95110250575009 8.145728643216081\n",
      "-16.030646734221644 -20.996152778095716 8.190954773869347\n",
      "-16.030646734221644 -20.892731816562325 8.236180904522612\n",
      "-16.030646734221644 -20.894066896730614 8.28140703517588\n",
      "-16.030646734221644 -21.007724663240943 8.326633165829147\n",
      "-16.030646734221644 -21.009025299728833 8.371859296482413\n",
      "-16.030646734221644 -21.01216221477924 8.417085427135678\n",
      "-16.030646734221644 -21.01710510789645 8.462311557788945\n",
      "-16.030646734221644 -21.014983021890455 8.507537688442211\n",
      "-16.030646734221644 -21.016208031732354 8.552763819095478\n",
      "-16.030646734221644 -21.012396399713907 8.597989949748744\n",
      "-16.030646734221644 -21.013034449348474 8.64321608040201\n",
      "-16.030646734221644 -21.016253998579874 8.688442211055277\n",
      "-16.030646734221644 -21.006107338225995 8.733668341708544\n",
      "-16.030646734221644 -21.005785678059887 8.77889447236181\n",
      "-16.030646734221644 -21.007206235081092 8.824120603015075\n",
      "-16.030646734221644 -21.004146918432102 8.869346733668342\n",
      "-16.030646734221644 -21.007170889010677 8.91457286432161\n",
      "-16.030646734221644 -21.00826276242419 8.959798994974875\n",
      "-16.030646734221644 -21.01810166737625 9.00502512562814\n",
      "-16.030646734221644 -21.019162230863916 9.050251256281408\n",
      "-16.030646734221644 -21.083360868317154 9.095477386934673\n",
      "-16.030646734221644 -21.077465796576227 9.14070351758794\n",
      "-16.030646734221644 -21.078517076081955 9.185929648241206\n",
      "-16.030646734221644 -21.079037165101987 9.231155778894472\n",
      "-16.030646734221644 -21.080059124071415 9.27638190954774\n",
      "-16.030646734221644 -21.104978219205865 9.321608040201005\n",
      "-16.030646734221644 -21.1058426886423 9.366834170854272\n",
      "-16.030646734221644 -21.110567605644725 9.412060301507537\n",
      "-16.030646734221644 -21.111525199609268 9.457286432160805\n",
      "-16.030646734221644 -21.112469472718395 9.50251256281407\n",
      "-16.030646734221644 -21.066154863415285 9.547738693467338\n",
      "-16.030646734221644 -21.066511767241785 9.592964824120603\n",
      "-16.030646734221644 -21.074814298351164 9.63819095477387\n",
      "-16.030646734221644 -21.075721076535178 9.683417085427136\n",
      "-16.030646734221644 -21.07661546615345 9.728643216080402\n",
      "-16.030646734221644 -21.07749767601852 9.773869346733669\n",
      "-16.030646734221644 -21.08126399272046 9.819095477386934\n",
      "-16.030646734221644 -21.08212737263425 9.864321608040202\n",
      "-16.030646734221644 -21.08297912459029 9.909547738693467\n",
      "-16.030646734221644 -21.08381944188997 9.954773869346734\n",
      "-16.030646734221644 -21.089703307229723 10.0\n",
      "score -16.030646734221644 index 1.0\n"
     ]
    }
   ],
   "source": [
    "maxes = -100\n",
    "index = -1\n",
    "for p in numpy.linspace(1,10,200):\n",
    "    knn = KNeighborsRegressor(n_neighbors = 5, weights = 'distance',metric = 'minkowski', p = p)\n",
    "    score = numpy.mean(cross_val_score(knn, X, y, cv=kf,scoring='neg_mean_squared_error'))\n",
    "    print(maxes, score,p)\n",
    "    if score > maxes:\n",
    "        print(maxes, score,p)\n",
    "        maxes = score\n",
    "        index = p\n",
    "print('score',maxes,'index',index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('perceptron-train.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.loc[:,1:]\n",
    "y_train = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('perceptron-test.csv', header = None)\n",
    "X_test = data.loc[:,1:]\n",
    "y_test = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.655"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron(random_state = 241)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_scaled,y_train)\n",
    "predictions2 = clf.predict(X_test_scaled)\n",
    "accuracy_score(y_test, predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18999999999999995"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.845-0.655\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
